# =============================================================================
# PowerMem Benchmark Server Configuration
# =============================================================================
# Copy this file to .env and modify the values according to your needs
# 
# This configuration is specifically for benchmark testing scenarios.
# For production use, refer to the root .env.example file.
# =============================================================================

# =============================================================================
# 1. LLM Configuration (Required)
# =============================================================================
# Choose your LLM provider: openai, qwen, siliconflow, ollama, vllm, anthropic, deepseek
LLM_PROVIDER=openai

LLM_API_KEY=your_api_key_here
# Adjust the model according to your provider
LLM_MODEL=gpt-4o
LLM_TEMPERATURE=0.2

## Keep the default settings, as modifications are generally not needed.
LLM_MAX_TOKENS=1000
LLM_TOP_P=0.8
LLM_TOP_K=50

# Default Base URLs for LLM providers, you can adjust if necessary
OPENAI_LLM_BASE_URL=https://api.openai.com/v1
QWEN_LLM_BASE_URL=https://dashscope.aliyuncs.com/api/v1
SILICONFLOW_LLM_BASE_URL=https://api.siliconflow.cn/v1
OLLAMA_LLM_BASE_URL=
VLLM_LLM_BASE_URL=
ANTHROPIC_LLM_BASE_URL=https://api.anthropic.com
DEEPSEEK_LLM_BASE_URL=https://api.deepseek.com

# =============================================================================
# 2. Embedding Configuration (Required)
# =============================================================================
# Choose your embedding provider: qwen, openai, siliconflow, huggingface, lmstudio, ollama
EMBEDDING_PROVIDER=qwen

EMBEDDING_API_KEY=your_api_key_here
# Adjust the model according to your provider
EMBEDDING_MODEL=text-embedding-v4
EMBEDDING_DIMS=1536

# Default Base URLs for embedding providers, you can adjust if necessary
QWEN_EMBEDDING_BASE_URL=https://dashscope.aliyuncs.com/api/v1
OPENAI_EMBEDDING_BASE_URL=https://api.openai.com/v1
SILICONFLOW_EMBEDDING_BASE_URL=https://api.siliconflow.cn/v1
HUGGINFACE_EMBEDDING_BASE_URL=
LMSTUDIO_EMBEDDING_BASE_URL=
OLLAMA_EMBEDDING_BASE_URL=

# =============================================================================
# 3. Database Configuration (Required)
# =============================================================================
# Choose your database provider: oceanbase, postgres
DATABASE_PROVIDER=oceanbase

# Vector search weights (0.0 to 1.0) - Benchmark specific
VECTOR_WEIGHT=0.5
FTS_WEIGHT=0.5

# -----------------------------------------------------------------------------
# OceanBase Configuration (used when DATABASE_PROVIDER=oceanbase)
# -----------------------------------------------------------------------------
OCEANBASE_HOST=127.0.0.1
OCEANBASE_PORT=2881
OCEANBASE_USER=root@sys
OCEANBASE_PASSWORD=your_password
OCEANBASE_DATABASE=ai_work
OCEANBASE_COLLECTION=powermem_collection

## Keep the default settings, as modifications are generally not needed.
OCEANBASE_INDEX_TYPE=HNSW
OCEANBASE_VECTOR_METRIC_TYPE=l2
OCEANBASE_TEXT_FIELD=document
OCEANBASE_VECTOR_FIELD=embedding
OCEANBASE_EMBEDDING_MODEL_DIMS=1536
OCEANBASE_PRIMARY_FIELD=id
OCEANBASE_METADATA_FIELD=metadata
OCEANBASE_VIDX_NAME=memories_vidx

# Sparse vector support (optional, only for OceanBase)
SPARSE_VECTOR_ENABLE=false

# -----------------------------------------------------------------------------
# PostgreSQL Configuration (used when DATABASE_PROVIDER=postgres)
# -----------------------------------------------------------------------------
POSTGRES_HOST=127.0.0.1
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password
POSTGRES_DATABASE=ai_work
POSTGRES_COLLECTION=memories

## Keep the default settings, as modifications are generally not needed.
POSTGRES_EMBEDDING_MODEL_DIMS=1536
POSTGRES_DISKANN=true
POSTGRES_HNSW=true

# =============================================================================
# 4. Application Configuration
# =============================================================================
# History database path for benchmark tracking
HISTORY_DB_PATH=history.db

# Configuration version
CONFIG_VERSION=v1.1

# =============================================================================
# 5. Token Counting Configuration (Benchmark specific)
# =============================================================================
# Enable token counting for benchmark metrics: "true" or "false"
TOKEN_COUNTING=true

# =============================================================================
# 6. Reranker Configuration (Optional)
# =============================================================================
# Reranker settings for improved search results
RERANKER_ENABLED=true
RERANKER_PROVIDER=qwen
RERANKER_MODEL=qwen3-rerank
RERANKER_API_KEY=your_api_key_here
# Reranker base URL (for Qwen provider, uses DASHSCOPE_BASE_URL)
# If not set, defaults to https://dashscope.aliyuncs.com/api/v1
# RERANKER_BASE_URL=https://dashscope.aliyuncs.com/api/v1

# =============================================================================
# 7. Sparse Embedding Configuration (Optional)
# =============================================================================
# Sparse embedding for hybrid search (only supported for OceanBase)
SPARSE_EMBEDDER_PROVIDER=qwen
SPARSE_EMBEDDER_API_KEY=your_api_key_here
SPARSE_EMBEDDER_MODEL=text-embedding-v4
SPARSE_EMBEDDING_BASE_URL=https://dashscope.aliyuncs.com/api/v1
SPARSE_EMBEDDER_DIMS=1536
